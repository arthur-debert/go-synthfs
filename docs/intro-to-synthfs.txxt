Intro to Synthfs

	Anything that writes to the filesystem is always a blind spot in development: hard to test, hard to reason about and has to be carefully managed and mocked. For non server-client software, like desktop applications , the file system is every where. 

    Synthfs gives you an api for lazy filesystem calls


1. Synthfs Core

	synthfs, a synthetic file system is a regular API allowing you to create, move, copy and remove  files, directories, links and archives with a regular form, giving you pure objects for the results.  

	with synthfs, you can develop and unitest you program side-effect free, joying the benefits of pure functions making handling the fs  way much simpler and safer.


    1.2. Operations
    
        This works through synthfs's operations: API calls representing changes to the file system. But unlike real sys-calls, these operations split the actual side effect from the call. When an operation is created, while the fs is not mutated, we can validate it: does the parent dir exists, do I have the right permissions and so on. Hence, you'd get, as expected, errors at operation creation time. 

        Having validation occur in operations is key, as it allows you program to run confidently that it will work, or notify users or other error handling scenarios at that time, when your program has the context for the operation.

        Operations give you a powerful tool: a side-effect code that are a lazy description of the change. It can be tested, passed around, composed in further operations and evaluated at a later time.

        Since the realization of the lazy operations is handled by synthfs, and is well tested, your application can be confident that you can sub it for the real things with ease.

        Operations can be though of as reverse receipt, you get a stub that you can convert for the real thing later. But operations are useless if you can't converting the stub, that is execute the changes.  

        That's why operations in synthfs are used: they follow fs semantics and are validated at multiple stages. Operations are validated when created (does the source file exist?), when added to batches (are there conflicts with other operations?), and before execution (has the file been modified since we created the operation?). For example an operation to copy a file will verify the source exists, compute a checksum of its contents, and later verify that checksum hasn't changed before actually copying.

        This layered validation means you get early feedback about obvious problems, while also catching subtle issues like concurrent file modifications. You can validate data and provide user feedback prior to the actual execution of the fs change, allowing you to program and test for errors in the same side-effect free way while giving timely feedback.


    1.3. Batches and Automatic Dependencies


        You can roll several operations into a batch. This has the obvious benefit of running and checking results for multiple ops at once, but they also allow for a nifty feature in synthfs: dependent operations. 

        When adding operations to the batch, synthfs automatically handles dependencies for you. Say you want to create a file deep/nested/file.txt - synthfs will automatically detect that the parent directories "deep" and "deep/nested" don't exist and create them first. You don't need to manually create directory operations; the system figures out what prerequisites each operation needs and resolves them automatically.

        This means you can think in terms of what you want to accomplish, not the step-by-step requirements. Want to copy a file to a location that doesn't exist yet? Just tell synthfs to copy it there, and it will create the necessary directory structure first.

        When you are ready, you can call batches.Run() and operations will be resolved for dependencies and executed in the correct order.


2. Model and Guarantees

	If it sounds  too good to be true, it's because it is.  Conceptually, fsynth works like a write ahead log, but one that you can postpone and start executing at your convenience.

	This is just not possible: you can't give guarantees for a file system's' state or behavior at an arbitrary point in the future, *while allowing* changes to the file system between the operation is created and executed. That's how real WAL works. By sequencing operations and being the exclusive executor of these, it can gives you a strong guarantee. 

	By synthfs is nothing like that: the operating system, the user, others applications can alter data between an operation's creation and execution.  It's critical to understand this: synthfs validation presumes no concurrent changes to file system.  

    This is a solid representation of the model, for a throrough one, see ./correctness.txxt

	
    2.1 No guarantees, it's all best effort optimistic .

        This has clear implications: synthfs is a useful tool and abstraction for tightly  controlled environments, and should never be used under concurrency (not even low concurrency) and mission critical data.  But for software that runs on the user's machine, in locations that the application controls, it's usually safe enough. If the execution encounters an issue : either because an operation files, or we detect a change to the data we're dealing with we'll stop and, to the best extend possible revert the previous state.  synthfs does some good sanity checking for conflicts and checking that data has not changed between scheduling and running (with some limits, not a true deep validation but for the files at hand). These are here to make sure that simple bugs (in synthfs and your app) are safer,  and as a sanity check. But don't see these as strong guarantees of any sort, because they are not.

	
    2.2. Restore: Budget-Controlled Backup System

        If a pipeline fails, that is, any of it's operations fail, the batch will halt. You can ask it to restore, that is, undo all previously successful steps in the pipeline, restoring your fs to it's initial condition (more caveats follow). 

        synthfs now includes a budget-controlled backup system. When you run operations in "restorable" mode, synthfs will automatically backup data that would be lost (like files being deleted or overwritten) up to a memory budget you specify (default 10MB). This means you get reliable restore capabilities for typical config files and small data operations, while avoiding unbounded memory usage.

        If a file is too large for the remaining backup budget, the operation will fail fast rather than proceeding without backup. This gives you predictable memory usage and clear feedback about what can be safely restored.

        This is helpful and will work most of the time, but, as we've already seen, these are optimistic best effort semantics. For an operation to fail, it's quite likely that something is changed, say, the on disk fs doesn't quite match our exceptions (we we've seen, we assume a world of zero concurrency of operation targets), which means that the likelihood of us successfully restoring it is not 100%.  

        That's also the reason for calling it restore, and not rollback, as the latter is often used in the context of transactions, giving you guarantees that synthfs doesn't have.

        If a restore fails, we stop whatever we are. 
    
 
	2.3 Correctness / Guarantess descriptions

		Since a full transactional and correct system is way beyond this project's scope (or needs, frankly) it's worth formalizing what the correctness best effors actually entail. 

			2.3.1. We don't change files, archives nor links whose content has changed between operation creation and execution.

				Say that hello.txt has the text "hi mom" . Then our very first operation overwrites the content with "time to go".  

				When we create the file operation we take note of the file's current content as "hi mom". At the execution time, the engine will check it's content before changing it. If someone / some thing has changed it, the operation will fail.

				The rational for this being the user has given us to make the "hi mom " -> "time to go" transformation, but no others. He expects the content to be "hi mom". As the expectation is broken, it's safer to just exit.  This holds true for deletion , move , etc . 

				For files and archives, we checksum. For links we use the links target as the content.

			2.3.2. On dependend operations validation

				Let's imagine the current scenario. 

					1. directory tmp/foo is empty.
					2. operation creates file /tmp/foo/hello.txt
					3. other operation copies the /tmp/foo/hello.txt somewhere else
					4. other operation deletes the /tmp/foo/hello.txt
					5.  operation copies the /tmp/foo/hello.txt

				When it comes to execution time, operations  can't be validated agains the initial fs state, as the hello.txt file does not exist in it.

				For this reason, pipelines track changes to the synthetic operations, keeping tab of files insertions, moves, deletions and it's contents. 

				This allows us to validate the pipeline. Not only we can be ok that operations 3 anf 4 should work, but we also know that operation 5 will fail.

				The engine keeps tabs of new paths, and their contents, and can do this safely.
	
 
	3. Restore System

		synthfs offers users the ability to restore changes in case a pipeline fails. Again, this is useful for the simple case, but it's critical that there is a clear understanding of what this actually entails. 

		For starters, this is not a rollback, and that's why it's called restore, to distance itself from the expectation that this is a real transactional model that can be safely rollbacked.

		When it all works well, restore will revert all operations until the failed one. This works in the following manner; every operation knows how to perform it's own opposite, that is it undo's it's actions. Move operations can move back to the previous path, create operations can delete the object created and so on.

		When restoring the execution engine will work from the last successful execution backwards. running it's own reverse operation.

		3.1. Budget-Controlled Backups

			The hardest case is deletion. In order to revert it, we must back it up.

			synthfs handles this through a budget system. When you enable "restorable" mode, you specify a backup budget (like 10MB). For operations that need to backup data (like deleting a file), synthfs will:

			1. Check if there's enough budget remaining for the backup
			2. If yes, backup the data and proceed with the operation  
			3. If no, fail the operation immediately with a clear error

			This means you never run out of memory unexpectedly, and you know upfront what can be safely restored.

		3.2. Recursive Directory Restoration  

			When deleting directories, synthfs will recursively backup all contents within the budget limits. This means deleting a directory with 50 small config files will backup all of them for restoration, while deleting a directory with one huge video file might fail budget validation.

			The restore operations use the same validation and execution pipeline as regular operations, so they benefit from the same dependency resolution and safety checks.

		3.3. Practical Usage

			For typical application scenarios (config files, small data files, directory restructuring), the default 10MB budget handles most real-world cases gracefully. For larger operations, you can increase the budget or run without restore capabilities if the performance cost isn't worth it.

			Remember: this is still best-effort. The restore will work most of the time, but concurrent filesystem changes or other unexpected conditions can still cause restore failures. It's a safety net, not a guarantee.
