Intro to Synthfs

	Anything that writes to the filesystem is always a blind spot in development: hard to test, hard to reason about and has to be carefully managed and mocked. For non server-client software, like desktop applications , the file system is every where.


1. Synthfs Core Ideas

	synthfs, a synthetic file system is a regular API allowing you to create, move, copy and remove  files, directories, links and archives with a regular form, giving you pure objects for the results.  

	with synthfs, you can develop and unitest you program side-effect free, joying the benefits of pure functions making handling the fs  way much simpler and safer.


    1.2. Operations
    
        This works through synthfs's operations: API calls representing changes to the file system. But unlike real sys-calls, these operations split the actual side effect from the call. When an operation is created, while the fs is not mutated, we can validate it: does the parent dir exists, do I have the right permissions and so on. Hence, you'd get, as expected, errors at operation creation time. 

        Having validation occur in operations is key, as it allows you program to run confidently that it will work, or notify users or other error handling scenarios at that time, when your program has the context for the operation.

        Operations give you a powerful tool: a side-effect code that are a lazy description of the change. It can be tested, passed around, composed in further operations and evaluated at a later time.

        Since the realization of the lazy operations is handled by synthfs, and is well tested, your application can be confident that you can sub it for the real things with ease.

        Operations can be though of as reverse receipt, you get a stub that you can convert for the real thing later. But operations are useless if you can't converting the stub, that is execute the changes.  

        That's why operations in synthfs are used: they follow fs semantics and are validated at their creation too. For example an operation to create the file hello.txt in directory $HOME/data will fail if the directory doesn't exist. And operation that moves files will verify that source and target exist and you have the right permissions.

        This means that you can validate data, and provide user feedback prior to the actual execution of the fs change, allowing you to program and tests for errors in the same side-effect free way while giving timely feedback.


    1.3. Pipelines


        You can roll several operations into a pipeline. This has the obvious
        benefit of running and checking results for multiple ops at once, but they also allow for a nifty feature in synthfs: dependent operations. 

        When adding operations to the pipeline, an operation can refer to a fs
        state that has been queued, but not on disk. Say that one operation
        creates a directory and the next is writing a file to said directory. With pipelines, fsynth can check that the directory to host the file exists as it will go over the operations, and since, another operation has created that directory, it can validate this one, since the file will be created on an existing directory.

        When you are ready, you can call pipeline.Run() and operations will be ran sequentially.


2. Model and Guarantees

	If it sounds  too good to be true, it's because it is.  Conceptually, fsynth works like a write ahead log, but one that you can postpone and start executing at your convenience.

	This is just not possible: you can't give guarantees for a file system's' state or behavior at an arbitrary point in the future, *while allowing* changes to the file system between the operation is created and executed. That's how real WAL works. By sequencing operations and being the exclusive executor of these, it can gives you a strong guarantee. 

	By synthfs is nothing like that: the operating system, the user, others applications can alter data between an operation's creation and execution.  It's critical to understand this: synthfs validation presumes no concurrent changes to file system.  


    2.1 No guarantees, it's all best effort optimistic .

        This has clear implications: synthfs is a useful tool and abstraction for tightly  controlled environments, and should never be used under concurrency (not even low concurrency) and mission critical data.  But for software that runs on the user's machine, in locations that the application controls, it's usually safe enough. If the execution encounters an issue : either because an operation files, or we detect a change to the data we're dealing with we'll stop and, to the best extend possible revert the previous state.

        synthfs does some good sanity checking for conflicts and checking that data has not changed between scheduling and running (with some limits, not a true deep validation but for the files at hand). These are here to make sure that simple bugs (in synthfs and your app) are safer,  and as a sanity check. But don't see these as strong guarantees of any sort, because they are not.

    2.2. Restore: Poor man's rollback

        If a pipeline fails, that is, any of it's operations fail, the pipeline
        will halt. You can ask it to restore, that is, undo all previously
        successful steps in the pipeline, restoring your fs to it's initial
        condition (more caveats follow). 

        This is helpful and will work most of the time, but, as we've already seen,
        these are optimistic best effort semantics. For an operation to fail, it's
        quite likely that something is changed, say, the on disk fs doesn't quite
        match our exceptions (we we've seen, we assume a world of zero concurrency
        of operation targets), which means that the likelihood of us successfully
        restoring it is not 100%.  

        That's also the reason for calling it restore, and not rollback, as the
        latter is often used in the context of transactions, giving you guarantees
        that synthfs doesn't have.

        If a restore fails, we stop whatever we are. 
    
	2.3 Correctness / Guarantess descriptions

		Since a full tranasacional and correct system is way beyond this project's scope (or needs, frankly) it's worth formalizing what the correctness best effors actually entail. 

			2.3.1. We don't change files, archives nor links whose content has changed between operation creation and execution.

				Say that hello.txt has the text "hi mom" . Then our very first operation overwrites the content with "time to go".  

				When we create the file operation we take note of the file's current content as "hi mom". At the execution time, the engine will check it's content before changing it. If someone / some thing has changed it, the operation will fail.

				The rational for this being the user has given us to make the "hi mom " -> "time to go" transformation, but no others. He expects the content to be "hi mom". As the expectation is broken, it's safer to just exit.  This holds true for deletion , move , etc . 

				For files and archives, we checksum. For links we use the links target as the content.

			2.3.2. On dependend operations validation

				Let's imagine thie current scenario. 

					1. dirctory tmp/foo is empty.
					2. opearation creates file /tmp/foo/hello.txt
					3. other opearation copyies the /tmp/foo/hello.txt somewheere else
					4. other operation deletes the /tmp/foo/hello.txt
					5.  operation copyies the /tmp/foo/hello.txt

				When it comes to execution time, operations 3+ can't be validated agains the intiial fs state, as the hello.txt file doesn not exist in it.

				For this reason, pipelines track changes to the synthetic operations, keeping tab of files insertions, moves, deletions and it's contents. 

				This allows us to validate the pipeline. Not only we can be ok that operations 3 anf 4 should work, but we alsoi know that operation 5 will fail.

				The engine keeps tabs of new paths, and their contents, and can do this safely.
	
	3. Restore

		synthfs offers users the abiliry to restore changes in case a pipeline fails. Again, this is useful for the simple case, but it's critical that there is a clear understanding of what this actually entails. 

		For starters, this is not a rollback, and that's why it's called restore, to distance itself from the expectation that this is a real transactional model that can be safetly rollbacked.

		When it all works well, restore will revert all operations until the failed one. This works in the following manner; every operation knows how to perform it's own opposite, that is it undo's it's acitons. Move operations can move back to the previous path, create opeations can delete the object created and so on. . 

		When restoring the execution engine will work from the last successful execution backwards. runnint it's own reverse operation.

		1. Limits

			The hardest case is deletion. In order to revert it, we must back it up. 

			

   
